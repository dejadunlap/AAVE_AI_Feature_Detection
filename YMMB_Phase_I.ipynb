{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwlO78iCIyg3"
      },
      "source": [
        "# YMMB Project: Evaluating the Usage of African-American Vernacular English in Large Language Models\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Deja Dunlap\n",
        "\n",
        "This project in designed to evaluate LLM, specifically the ChatGPT 4o, Gemma 2.7, and the Llama 3 models, ability to understand grammatical features and usage of Non-\"Standard\" Dialects, specifically African American Vernacular English. We focus on the grammatical features: \"ain't\", the negative module, and the expletive \"be\".\n",
        "\n",
        "The first phrase of the project was to evaluate how well ChatGPT usage of grammatical features in comparison to human usage. To do this, we prompted ChatGPT to create a dialogue as if they were an African American from one of the cities represented in the dataset. We did this 1000 times and evaluate how often the previously mentioned grammatical features occured and compared it to human use.\n",
        "\n",
        "The next stage was analyzing the context in which the feature regulary occurs by speakers of AAVE. for the feature 'aint', we determine the 10 most likely words the precede ain't and the probability that ain't will follow any of those given words ( ie. P(ain't | word)) . From there, we compare that to the probabilities that ChatGPT assigns to the \"ain't' following the word given some preceding sentence containing some element of AAVE to make it \"speak\" in the dialect. For the feature expletive \"be\" it was much the similar process for ain't. For the negative module, we evaluated the percentage of sentences in the human dataset that contained the negative feature. When prompting the model, we had the model prompt an entire sentence multiple times and evaluated how often it had the feature.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rIVW9aEXfdy1",
        "outputId": "9464f0f1-7ca3-49b7-b1a5-8a1306f8836a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stanza in /usr/local/lib/python3.11/dist-packages (1.10.1)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (from stanza) (2.14.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from stanza) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.11/dist-packages (from stanza) (5.29.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from stanza) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from stanza) (3.4.2)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from stanza) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stanza) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (4.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.3.0->stanza) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3.0->stanza) (3.0.2)\n",
            "Requirement already satisfied: together in /usr/local/lib/python3.11/dist-packages (1.5.8)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.11/dist-packages (from together) (3.11.15)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from together) (8.2.1)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from together) (0.2.2)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.11/dist-packages (from together) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from together) (2.0.2)\n",
            "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from together) (11.2.1)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from together) (18.1.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from together) (2.11.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: rich<15.0.0,>=13.8.1 in /usr/local/lib/python3.11/dist-packages (from together) (13.9.4)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.11/dist-packages (from together) (4.67.1)\n",
            "Requirement already satisfied: typer<0.16,>=0.9 in /usr/local/lib/python3.11/dist-packages (from together) (0.15.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.20.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.8.1->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.8.1->together) (2.19.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.8.1->together) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package english_wordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package english_wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Package pe08 is already up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets_json to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "!pip install stanza\n",
        "!pip install together\n",
        "\n",
        "# dowloading the dependecies need for this project\n",
        "import re\n",
        "import os\n",
        "from together import Together\n",
        "import torch\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "import random\n",
        "from google.colab import files\n",
        "import openai\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "from google.colab import userdata\n",
        "\n",
        "nltk.download('all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hNsEfL7MDHS"
      },
      "source": [
        "## Using GPUs in Colab\n",
        "\n",
        "LLMs run much faster on GPUs to attach you Colab to a GPU use the follow steps:\n",
        "\n",
        "\n",
        "1.   Click \"Runtime\" in the menu at the top\n",
        "2.   Click \"Change runtime type\"\n",
        "3.   Select \"T4 GPU\"\n",
        "4.   Click \"Save\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eje2xOeGfqMF",
        "outputId": "64e9a58c-9af1-43bd-bf9f-86f7c13191e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# checking if cuda is active\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "\n",
        "# setting the GPU as the device we are using\n",
        "device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkNfsgTcfvCv"
      },
      "outputs": [],
      "source": [
        "class AAVE_Feature:\n",
        "\n",
        "    def __init__(self, folder):\n",
        "        self.folder = folder\n",
        "        self.dataset = \"\"\n",
        "        self.bigrams = []\n",
        "        self.feature_prob = {}\n",
        "        self.feature_density = {\"be\": 0, \"negative\": 0, \"ain't\": 0}\n",
        "        self.sentiment = [0, 0]\n",
        "        self.files_count = 0\n",
        "\n",
        "    \"\"\"\n",
        "    Input: none\n",
        "    Output: none\n",
        "    Function reads in the files from the folder and returns the cleaned version of the text from them\n",
        "    \"\"\"\n",
        "    def read_files(self, sentiment = False, word_count = False, human = False):\n",
        "      # going through the files\n",
        "      for root, _, files in os.walk(self.folder):\n",
        "        self.files_count += len(files)\n",
        "        for file in files:\n",
        "          file_path = os.path.join(root, file)\n",
        "          # ignore the checkpoint folder (model generated datasets)\n",
        "          if \"checkpoints\" in file_path:\n",
        "            continue\n",
        "          # clean the data\n",
        "          cleaned = self.clean_data(file_path, human)\n",
        "          # add to dataset\n",
        "          self.dataset += cleaned\n",
        "\n",
        "        # print out number of words, sentences across dataset\n",
        "        if word_count:\n",
        "          print(\"Words: \" + str(len(self.dataset)))\n",
        "          print(\"Sentences: \" + str(len(self.dataset.split(\".\"))))\n",
        "\n",
        "        # print out sentiment [positive, negative] of dataset\n",
        "        if sentiment:\n",
        "         self.sentiment[0] /= self.files_count\n",
        "         self.sentiment[1] /= self.files_count\n",
        "\n",
        "    \"\"\"\n",
        "    Input: text (str)\n",
        "    Output: None\n",
        "    Calculates the sentiment of the tex as well as returns the top bigrams\n",
        "    \"\"\"\n",
        "    def content_analysis(self, text):\n",
        "      # prepocessing the text\n",
        "      tokens = word_tokenize(text.lower())\n",
        "      filtered_tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
        "      lemmatizer = WordNetLemmatizer()\n",
        "      lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
        "\n",
        "      # rejoining the processed version of the text\n",
        "      processed_text = ' '.join(lemmatized_tokens)\n",
        "\n",
        "      # sentiment analysis\n",
        "      analyzer = SentimentIntensityAnalyzer()\n",
        "      self.sentiment[0] += analyzer.polarity_scores(processed_text)['pos']\n",
        "      self.sentiment[1] += analyzer.polarity_scores(processed_text)['neg']\n",
        "\n",
        "    \"\"\"\n",
        "    Input: file (str)\n",
        "    Output: None\n",
        "    Returns the density of the grammatical feature in the dataset\n",
        "    \"\"\"\n",
        "    def feature_densities(self, feature):\n",
        "      if feature == \"ain't\":\n",
        "        self.feature_density[\"ain't\"] = (self.dataset.count(\"ain't\")/ len(self.dataset.split('.')))\n",
        "      elif feature == \"negative\":\n",
        "        self.feature_density[\"negative\"] = (self.double_negatives(self.dataset) / len(self.dataset.split('.')))\n",
        "      elif feature == \"be\":\n",
        "        self.feature_density[\"be\"] =  (self.feature_density[\"be\"] / len(self.dataset.split('.')))\n",
        "\n",
        "    \"\"\"\n",
        "    Input: file (str)\n",
        "    Output: cleaned_text (str)\n",
        "    Returns the parts of the interviews with just the speakers of AAVE and removes non alphnumeric characters (except periods and commas) from the text\n",
        "    \"\"\"\n",
        "    def clean_data(self, file, human = True):\n",
        "        interview = []\n",
        "        with open(file, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "          if human:\n",
        "            for line in file:\n",
        "                line = line.split('\\t')\n",
        "                if len(line) < 4:\n",
        "                    continue\n",
        "                speaker = line[1]\n",
        "                content = line[3]\n",
        "\n",
        "                # only pulling the lines of the dataset that are spoken by the speaker (se means speaker) and are actual pieces of content (data also contains things like pauses)\n",
        "                if \"se\" in speaker and \"(pause \" not in content:\n",
        "                    interview.append(line[3])\n",
        "          else:\n",
        "            for line in file:\n",
        "              interview.append(line)\n",
        "\n",
        "        # joining all of the text together\n",
        "        text = \" \".join(interview)\n",
        "        cleaned_text = re.sub(r\"[^\\w\\s'.]\", '', text)\n",
        "        #self.content_analysis(cleaned_text)\n",
        "\n",
        "        return cleaned_text.lower()\n",
        "\n",
        "    \"\"\"\n",
        "    Input: None\n",
        "    Return: examples (arr)\n",
        "    Returns 10 random sentences from the dataset\n",
        "    \"\"\"\n",
        "    def ran_sentences(self, count = 10):\n",
        "      dataset = self.dataset.split(\".\")\n",
        "      random.shuffle(dataset)\n",
        "      examples = dataset[:count]\n",
        "      return examples\n",
        "\n",
        "    \"\"\"\n",
        "    Input: text (str), window (int OPTIONAL)\n",
        "    Return: n_grams (arr)\n",
        "    Returns n_grams of window size (default is 2)\n",
        "    \"\"\"\n",
        "    def n_grams(self, window = 2):\n",
        "        words = self.dataset.split(\" \")\n",
        "        n_grams = []\n",
        "        for idx in range(len(words) - 1):\n",
        "            n_grams.append(words[idx:idx+window])\n",
        "        self.bigrams = n_grams\n",
        "\n",
        "    \"\"\"\n",
        "    Input: Key (string), k (int)\n",
        "    Output: top_pre (dict)\n",
        "    Goes through the bigrams and finds all of the bigrams that contain the key, find and return common words preceded it , and returns the probabiltity of the feature after the word (depending on the task)\n",
        "    \"\"\"\n",
        "    def top_k_bigrams(self, key, k, human=True, human_key = None):\n",
        "\n",
        "        # constructing bigrams from the dataset\n",
        "        self.n_grams()\n",
        "\n",
        "        # finding all the bigrams that contain the key word\n",
        "        key_count = 0\n",
        "        preceding = {}\n",
        "\n",
        "        for bigram in self.bigrams:\n",
        "            if key == \"be\":\n",
        "              if '' not in bigram and bigram[1] == \"be\" and pos_tag([bigram[0]])[0][1] in [\"NN\", \"NNP\", \"NNS\", \"PRP\"] and \"'\" not in bigram[0] and bigram[0] not in [\"couldn't\", \"wanna\", \"um\", \"can't\", \"gonna\", \"could\", \"should\", \"uh\", \"gotta\", \"sposta\"]:\n",
        "                preceding[bigram[0]] = preceding[bigram[0]] + 1 if bigram[0] in preceding else 1\n",
        "                self.feature_density[\"be\"] += 1\n",
        "            elif key in bigram:\n",
        "              if bigram[1] == key:\n",
        "                preceding[bigram[0]] = preceding[bigram[0]] + 1 if bigram[0] in preceding else 1\n",
        "\n",
        "        # focusing only on the words that regular occur next to key\n",
        "        top_pre = {}\n",
        "        if human:\n",
        "          sorted_preceding = sorted(preceding.items(), key=lambda item: item[1], reverse=True)\n",
        "          top_pre = dict(sorted_preceding[:k])\n",
        "        else:\n",
        "          for key in preceding.keys():\n",
        "            if key in human_key:\n",
        "              top_pre[key] = preceding[key]\n",
        "\n",
        "        return top_pre\n",
        "\n",
        "    \"\"\"\n",
        "    Input: text (str)\n",
        "    Return: neg_sentence (int)\n",
        "    Returns the negative of times the negative module was present in the text\n",
        "    \"\"\"\n",
        "    def double_negatives(self, text):\n",
        "      # List of common negation words\n",
        "      negation_words = r\"\\b(no|not|never|none|nothing|nowhere|nobody|neither|nor|ain't|can't|won't|don't|isn't|aren't|hasn't|haven't|hadn't)\\b\"\n",
        "      neg_sentence = 0\n",
        "      # Find all negations\n",
        "      for sentence in text.split('.'):\n",
        "        negations = re.findall(negation_words, sentence, re.IGNORECASE)\n",
        "        neg_sentence += (len(negations) >= 2)\n",
        "\n",
        "      return neg_sentence\n",
        "\n",
        "    \"\"\"\n",
        "    Input: key (string), feature (string)\n",
        "    Return: combo_count (float)\n",
        "    Returns context-specific feature probabilites of 'be' and 'aint' feature\n",
        "    \"\"\"\n",
        "    def prob_word(self, key, feature):\n",
        "\n",
        "      # find the total number of times the preceding word appears in the dataset [p(word)]\n",
        "      word_count = self.dataset.count(key)\n",
        "\n",
        "      # determine the probabilities of given grammatical feature depending on the feature [p(key | word)]\n",
        "      combo_count = 0\n",
        "      for bigram in self.bigrams:\n",
        "        if '' in bigram:\n",
        "            continue\n",
        "\n",
        "        if feature == \"ain't\":\n",
        "          if bigram == [key, feature]:\n",
        "              combo_count += 1\n",
        "        elif feature == \"be\":\n",
        "          if bigram == [key, feature]:\n",
        "              combo_count += 1\n",
        "        elif feature == \"negative\":\n",
        "          combo_count = self.feature_density[\"negative\"]\n",
        "\n",
        "\n",
        "      if feature == \"ain't\" or feature == \"be\":\n",
        "        return combo_count / word_count\n",
        "      else:\n",
        "        return combo_count\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Input: none\n",
        "    Output: none\n",
        "    Goes through the bigrams and finds all of the bigrams that contain feature, find and return common words preceded and following it, and returns the probabiltity of aint either before or after the word (depending on the task)\n",
        "    \"\"\"\n",
        "    def lexical_feature(self, feature, human=True, human_keys = None):\n",
        "\n",
        "        # if from the human data -  finding the top k words that common preceding/follow the feature word of interest\n",
        "        # if from the model data - finding the probabilities of the most commoning preceding words from the human dataset\n",
        "        human_pre = self.top_k_bigrams(feature, 10, human, human_keys)\n",
        "\n",
        "        if feature == \"ain't\" or feature == \"be\":\n",
        "          self.feature_prob[feature] = {key: self.prob_word(key, feature) for key in human_pre.keys()}\n",
        "        else:\n",
        "          self.feature_prob[feature] = self.prob_word(\"\", feature)\n",
        "\n",
        "    \"\"\"\n",
        "    Input: none\n",
        "    Output: none\n",
        "    Samples the model to create 'sociololinguistic interview' as a user from one of the cities in the human dataset - stores output in file\n",
        "    If looking to extend model to one of the other models in the Together API model, just need to receive the model tag, else must add other models API\n",
        "    Must have own API key for either models to run from python terminal\n",
        "    \"\"\"\n",
        "    def model_data(self, model = 'meta', n = 1000):\n",
        "      STORY_PROMPT = \"\"\"Produce a narrative as if you were an African American {gender} from {city} where you are being recorded for a sociolinguistic interview. Create a piece of text equivalent in length to talking for about 30 minutes. Include only the text for the prompt. Do not include any other extraneous information (including the phrase \"Here's the prompt\" or any of it's varieties).\"\"\"\n",
        "      for i in range(1000):\n",
        "        gender = random.choice([\"Female\", \"Male\"])\n",
        "        city = random.choices(population=[\"Atlanta\", \"DC\", \"Detroit\", \"Lower East Side of New York City\", \"Princeville\", \"Rochester\", \"Valdosta\"], weights=[0.05, 0.5, 0.14, 0.05, 0.11, 0.06, 0.05], k=1)[0]\n",
        "        prompt = STORY_PROMPT.format(gender=gender, city=city)\n",
        "        models = {'meta':\"meta-llama/Meta-Llama-3-8B-Instruct-Turbo\" , 'deepseek': 'deepseek-ai/DeepSeek-R1', 'google': 'google/gemma-2-27b-it'}\n",
        "        if model in ['google', 'meta']:\n",
        "          client = Together(api_key=userdata.get('TOGETHER_API_KEY'))\n",
        "          response = client.chat.completions.create(\n",
        "              model=models[model],\n",
        "              messages=[{\"role\": \"user\", \"content\": prompt}]          )\n",
        "        else:\n",
        "          openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "          client = openai.OpenAI(api_key = openai.api_key)\n",
        "          response = client.chat.completions.create(\n",
        "              model=\"gpt-4o-mini\",\n",
        "              store=True,\n",
        "              messages=[{\"role\": \"user\", \"content\": prompt}])\n",
        "\n",
        "        directory = self.folder\n",
        "        if not os.path.exists(directory):\n",
        "          os.makedirs(directory)\n",
        "        file_name = directory + str(city) + \"_\" + str(gender) + \"_\" + str(i) + \".txt\"\n",
        "        with open(file_name, 'w') as file:\n",
        "          file.write(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Model Data\n",
        "\n",
        "Running the following code segment will generate a new batch of model generate test for evaluation. Pass in which model you would like to be generated and the number of samples you would like to creat."
      ],
      "metadata": {
        "id": "ORM7T6plvv2k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlIh5obV_yQ7"
      },
      "outputs": [],
      "source": [
        "# create the model datasets, prompting the model to create sociolinguistic interviews based off of the demographics represented in the human dataset\n",
        "# pass in folder that you want the data to be created in\n",
        "model_AAVE = AAVE_Feature(folder = \"./openai_data\")\n",
        "\n",
        "# uncomment to generate the sociolinguistic interview from model\n",
        "#model_AAVE.model_data(model = \"openai\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fyHiNfXOf19X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "816071af-2313-47cd-a7e8-cf50764b3faa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/model_data'\n",
            "/content\n",
            "  adding: openai_data/ (stored 0%)\n",
            "  adding: openai_data/openai_data/ (stored 0%)\n",
            "  adding: openai_data/openai_data/DC_Female_297.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/ (stored 0%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/ (stored 0%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_107.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_379.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_411.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Male_4.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_392.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_359.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Male_385.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_166.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Valdosta_Male_440.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_97.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_349.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Male_110.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_308.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_60.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_235.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_190.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_7.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_196.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_216.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_395.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_260.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_162.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_54.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_405.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_401.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Female_319.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_179.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_298.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Valdosta_Female_334.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_435.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_10.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_387.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_310.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_326.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_80.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_396.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_320.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_282.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Female_138.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_279.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Male_94.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Male_434.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_67.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Valdosta_Male_137.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_347.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_437.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_70.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Valdosta_Male_242.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Female_398.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_378.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_442.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_433.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_30.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_93.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_126.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_35.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_15.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_142.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_3.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_270.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_341.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_121.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_78.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_234.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_26.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_37.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_361.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Female_56.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_139.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_338.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Valdosta_Male_275.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_52.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Male_6.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_307.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_74.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_53.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Male_312.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_254.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_363.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_402.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_19.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_375.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_16.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_31.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Male_302.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Valdosta_Male_22.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Male_364.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_274.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_226.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_272.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_251.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_232.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_130.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_48.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Female_180.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_426.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_289.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_220.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_204.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_20.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_85.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_213.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_39.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Male_350.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_146.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Male_98.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_268.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_217.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_133.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Male_32.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_28.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_206.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_34.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_400.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_261.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_306.txt (deflated 51%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_212.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_17.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_280.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_413.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Female_258.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_170.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_203.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_86.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_273.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_154.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_194.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_38.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_393.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_140.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Male_367.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_348.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_291.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_262.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_134.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_160.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_297.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_247.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_59.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Valdosta_Male_406.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Female_267.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Male_61.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_225.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_209.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Female_89.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_211.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_410.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_76.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_391.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_2.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_189.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_191.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_384.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_414.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_29.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Female_248.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Female_116.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_381.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_345.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_155.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_157.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_99.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_340.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_236.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Female_408.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_278.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_333.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_373.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_156.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_88.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Valdosta_Female_13.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_62.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_394.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Female_199.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_215.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_415.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_259.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_370.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Female_316.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Female_255.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_192.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_182.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_439.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_95.txt (deflated 57%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_104.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_383.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_147.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_18.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_276.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_374.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_40.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Male_342.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_92.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_263.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_125.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_399.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_429.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_0.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_49.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_75.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_438.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_336.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Female_292.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_141.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_11.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_404.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Male_371.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_27.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Female_24.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_55.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_372.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_103.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_43.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_419.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_386.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_33.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_9.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Female_444.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_108.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_145.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_295.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_356.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_244.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_82.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_417.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_441.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Male_318.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_25.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Male_171.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_321.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_352.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_223.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_144.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_421.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_376.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_328.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_314.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_412.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_327.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Female_317.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_167.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_250.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_287.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_290.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_300.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Valdosta_Male_183.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Female_436.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_102.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_227.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_266.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_161.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_407.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Female_115.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Female_425.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_344.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_448.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_430.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Female_424.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_105.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_230.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_159.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Male_277.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_58.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_271.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_172.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_299.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_420.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_8.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_362.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_198.txt (deflated 51%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_44.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_113.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Male_285.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_296.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_71.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_12.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_388.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Male_186.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Female_207.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_222.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Valdosta_Female_164.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_238.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_447.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_337.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_283.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_150.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_231.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_195.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_117.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_46.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_165.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_57.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_118.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_382.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_169.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_202.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Male_87.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_240.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_390.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_245.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_205.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_351.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_366.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_69.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_449.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Male_83.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_355.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_64.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_369.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_357.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_14.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_445.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_132.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_249.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Male_339.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_303.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_181.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_50.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_281.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_389.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_228.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Female_311.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_91.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_65.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_23.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_21.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_325.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Valdosta_Female_106.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_178.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_409.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Male_149.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_119.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_63.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_360.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Female_239.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_173.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_253.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_120.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Female_219.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_265.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_427.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Male_174.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Female_143.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_148.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_422.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_81.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_229.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_124.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_365.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_358.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_210.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_175.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_168.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_443.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_343.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_309.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_36.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Male_90.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_241.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_432.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Female_163.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_73.txt (deflated 51%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_218.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_193.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Male_68.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_151.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_201.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Female_51.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_423.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_252.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_368.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_257.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Valdosta_Female_188.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Female_335.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_305.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_131.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_329.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_112.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_158.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Male_109.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_237.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_431.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_66.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_45.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_152.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_377.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Valdosta_Male_42.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_41.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Male_293.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Male_324.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Female_288.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_264.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Female_246.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_127.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_47.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_284.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_346.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_428.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Male_233.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_128.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Male_177.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Female_114.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_224.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Male_200.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_197.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_353.txt (deflated 51%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_286.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_208.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_221.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_330.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_294.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Valdosta_Male_123.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Male_322.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_301.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_184.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_122.txt (deflated 51%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Valdosta_Female_380.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Male_416.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Male_269.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_79.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_96.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Male_84.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_187.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_354.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_214.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_5.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_111.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_403.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Male_418.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Valdosta_Male_313.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Female_185.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_446.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Princeville_Female_331.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_136.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_176.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_77.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Valdosta_Female_397.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_1.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_72.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Female_101.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Lower East Side of New York City_Male_304.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_315.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Female_323.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_129.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Detroit_Male_153.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Rochester_Female_100.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Atlanta_Female_256.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_243.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/DC_Male_332.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (2)/openai_data/Valdosta_Male_135.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_240.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_391.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_359.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Male_447.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Female_89.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_324.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_212.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_206.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/DC_Female_9.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Male_306.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Valdosta_Male_358.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_431.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_105.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_4.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Female_103.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Atlanta_Male_409.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Male_414.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Atlanta_Female_112.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_326.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_405.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_141.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_442.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_434.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_305.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_90.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_387.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_310.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_80.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Rochester_Female_235.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_21.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/DC_Female_246.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_277.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/ (stored 0%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/ (stored 0%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Lower East Side of New York City_Female_37.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Female_85.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Female_60.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_33.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_62.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_96.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_84.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_56.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_70.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_98.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Male_40.txt (deflated 57%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Atlanta_Male_15.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Atlanta_Male_99.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_30.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Rochester_Female_16.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_26.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_97.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_83.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Lower East Side of New York City_Female_65.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Atlanta_Male_46.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Rochester_Female_81.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Female_2.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_20.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Lower East Side of New York City_Male_25.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Princeville_Female_74.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_34.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_17.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Female_8.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_69.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_52.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_38.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Male_79.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_44.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_73.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_23.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Princeville_Female_53.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_59.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Atlanta_Male_82.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Valdosta_Female_41.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_51.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_91.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Female_78.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_58.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_4.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Princeville_Male_92.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Female_14.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_72.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_95.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Female_49.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_55.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Princeville_Female_42.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Atlanta_Male_12.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Male_48.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Rochester_Male_9.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Rochester_Female_19.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Princeville_Female_6.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_86.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_1.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_88.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Male_28.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Valdosta_Male_61.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_39.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Valdosta_Male_50.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Female_29.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_90.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_18.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Female_3.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_32.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_77.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_57.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Princeville_Female_21.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_94.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Female_7.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Male_27.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_63.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_43.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_24.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Lower East Side of New York City_Female_71.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Female_89.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Male_64.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Atlanta_Male_45.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Rochester_Male_11.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_35.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_36.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Princeville_Male_87.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Lower East Side of New York City_Male_68.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Female_0.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Male_66.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Princeville_Female_93.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_22.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_76.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_67.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_47.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Female_5.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Rochester_Male_75.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_31.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Detroit_Female_10.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/DC_Male_80.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Atlanta_Male_13.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/openai_data (1)/openai_data/Princeville_Male_54.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_96.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_376.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_385.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_66.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Atlanta_Male_78.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_8.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_347.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Rochester_Female_419.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_395.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Rochester_Male_230.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_415.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_173.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_433.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_329.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_72.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_35.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_390.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Male_140.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_331.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/Rochester_Female_134.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_121.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_332.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_436.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_234.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_26.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_13.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_37.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_102.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_263.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_6.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_54.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_404.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_319.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Female_402.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_344.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_435.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_98.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_407.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/Atlanta_Female_43.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_157.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_65.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_369.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_408.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_181.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Valdosta_Female_202.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_340.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/Rochester_Female_36.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_250.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_261.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Valdosta_Male_327.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_19.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_410.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_200.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_292.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_3.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_92.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_31.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_412.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_226.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_272.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Atlanta_Male_249.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_232.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_189.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Rochester_Male_210.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_443.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_394.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_184.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_289.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Valdosta_Female_424.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_46.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_204.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_82.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_20.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/DC_Female_162.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_127.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_247.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/DC_Male_213.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Valdosta_Male_342.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_302.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_268.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_352.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_252.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_190.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Atlanta_Male_1.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_437.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_296.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_288.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_183.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_367.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Valdosta_Male_334.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_293.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Female_130.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_128.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Male_339.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Valdosta_Female_254.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_88.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_280.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Valdosta_Female_50.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_303.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_12.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_225.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_328.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/DC_Female_170.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_182.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_425.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_111.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_52.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_278.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_68.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Male_39.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Valdosta_Female_7.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_315.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_110.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_283.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_142.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_265.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_291.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_262.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_155.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_160.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_309.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_59.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_323.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Atlanta_Female_421.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Rochester_Female_267.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Rochester_Male_284.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Rochester_Female_325.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_73.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_51.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_211.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_381.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Rochester_Female_30.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_353.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_322.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_341.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_67.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_118.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Valdosta_Male_194.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_259.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_91.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_392.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_411.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Atlanta_Female_382.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Male_106.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_384.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_175.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_365.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_399.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/DC_Male_27.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Rochester_Female_386.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Valdosta_Female_337.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/Atlanta_Male_432.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_260.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_236.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_245.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Male_185.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_449.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_53.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Male_114.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_203.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_139.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_264.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_364.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_223.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_79.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_333.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_148.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_120.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_135.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_215.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Atlanta_Male_244.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_156.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Rochester_Male_108.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_57.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_286.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_374.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_95.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Valdosta_Male_164.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_159.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_18.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_275.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_153.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_137.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_255.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_383.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_429.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_430.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_17.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_209.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_76.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_93.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Rochester_Female_5.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_269.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_396.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_75.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_438.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Female_403.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/DC_Male_248.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Female_281.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/DC_Male_196.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_192.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_11.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Female_237.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_238.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_330.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_420.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Valdosta_Male_152.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_207.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_179.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_312.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Rochester_Male_426.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_258.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_356.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_10.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_48.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_348.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Rochester_Male_357.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_193.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_441.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Atlanta_Male_379.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Rochester_Male_171.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Valdosta_Male_178.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Rochester_Male_146.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_15.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_144.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_253.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Male_380.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_138.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_40.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_257.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_304.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_318.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/DC_Female_445.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_186.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Rochester_Male_2.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_373.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_366.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_279.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_61.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/Valdosta_Female_104.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_448.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_416.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_14.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_150.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_167.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_58.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_439.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_299.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_417.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_32.txt (deflated 57%)\n",
            "  adding: openai_data/openai_data/Rochester_Male_63.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_227.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_362.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_198.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_44.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Rochester_Male_345.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_113.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_224.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Atlanta_Female_290.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_158.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Valdosta_Male_70.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_214.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_308.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_177.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Rochester_Male_375.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Male_422.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/DC_Female_34.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_122.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_222.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_418.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Male_282.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_231.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Female_60.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_123.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_169.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_77.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_143.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_117.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/DC_Male_313.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Rochester_Male_29.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_199.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_218.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Rochester_Male_87.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_321.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_361.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_351.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_266.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_444.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_229.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Valdosta_Male_125.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_132.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_239.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Male_84.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_371.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_273.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_274.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_338.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_38.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_24.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Valdosta_Female_343.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_256.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/Atlanta_Male_16.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_389.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_228.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Rochester_Female_300.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_413.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Rochester_Female_191.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_23.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_401.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_49.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_350.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_115.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/DC_Female_97.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_124.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_119.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_360.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_295.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_427.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_131.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_165.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Atlanta_Male_363.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Female_74.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_129.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_276.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_241.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_62.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/DC_Female_233.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_298.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_151.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_201.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_83.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_355.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_423.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_271.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_368.txt (deflated 52%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_55.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_314.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_398.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_188.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Rochester_Male_81.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_136.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_400.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_446.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_377.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_317.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/Rochester_Male_316.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_168.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_163.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_440.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Female_25.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_109.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/DC_Female_41.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Atlanta_Male_147.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_251.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_285.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_145.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Valdosta_Female_336.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Valdosta_Female_195.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_116.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_56.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Atlanta_Male_242.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Atlanta_Female_406.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Atlanta_Female_205.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_42.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/DC_Female_346.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_217.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_22.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_294.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_100.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_428.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_335.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/DC_Female_397.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Valdosta_Male_133.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Female_197.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_208.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Atlanta_Male_219.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_221.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_0.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_372.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_99.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_301.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Valdosta_Female_311.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_180.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Atlanta_Male_107.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_161.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_220.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_287.txt (deflated 56%)\n",
            "  adding: openai_data/openai_data/DC_Male_71.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_45.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_270.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_126.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_47.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_187.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Female_354.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_64.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_370.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Valdosta_Male_28.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_378.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_174.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Valdosta_Female_85.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Lower East Side of New York City_Male_349.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_307.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/DC_Male_393.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Atlanta_Male_176.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_388.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Rochester_Female_86.txt (deflated 53%)\n",
            "  adding: openai_data/openai_data/Atlanta_Male_166.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Female_69.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Detroit_Male_172.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_101.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Princeville_Male_320.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_94.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/DC_Male_149.txt (deflated 55%)\n",
            "  adding: openai_data/openai_data/Princeville_Female_216.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Male_243.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/DC_Female_154.txt (deflated 54%)\n",
            "  adding: openai_data/openai_data/Atlanta_Female_33.txt (deflated 54%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ac2397ef-197e-4776-b6fd-975a2d692ca3\", \"openai_data.zip\", 3013343)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# download data to computer\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "%cd /content/drive/MyDrive/model_data\n",
        "\n",
        "!zip -r openai_data.zip openai_data/\n",
        "\n",
        "files.download('openai_data.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG8s6nB5Nkj2"
      },
      "source": [
        "# Download the Data\n",
        "\n",
        "The following code snippet will request that you upload a file. Upload either the human dataset or one of the model datasets to test for feature densities + context-based usage.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "# Unzip the file\n",
        "!unzip final_openai_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "collapsed": true,
        "id": "pFb14ziusl55",
        "outputId": "e8e01dac-8bfb-4c1b-dff3-0e770680f0c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c276632c-c46f-4bb7-a71c-8804ccae3b6c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c276632c-c46f-4bb7-a71c-8804ccae3b6c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving final_openai_data.zip to final_openai_data (1).zip\n",
            "Archive:  final_openai_data.zip\n",
            "replace openai_data/openai_data/Atlanta_Female_112.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "# Unzip the file\n",
        "!unzip meta_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LSAoKXZEvFVi",
        "outputId": "254521d5-29f0-4280-8093-af6c2c72fefb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1f3dc9bf-0292-49db-9a9e-ca43313d2d97\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1f3dc9bf-0292-49db-9a9e-ca43313d2d97\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving meta_data.zip to meta_data.zip\n",
            "Archive:  meta_data.zip\n",
            "   creating: deepseek_data/\n",
            "  inflating: deepseek_data/DC_Female_896.txt  \n",
            "  inflating: deepseek_data/DC_Female_324.txt  \n",
            "  inflating: deepseek_data/DC_Female_128.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_602.txt  \n",
            "  inflating: deepseek_data/DC_Female_250.txt  \n",
            "  inflating: deepseek_data/DC_Female_383.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_168.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_174.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_371.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_987.txt  \n",
            "  inflating: deepseek_data/DC_Male_725.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_116.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_282.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_882.txt  \n",
            "  inflating: deepseek_data/DC_Male_562.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_958.txt  \n",
            "  inflating: deepseek_data/DC_Female_743.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_249.txt  \n",
            "  inflating: deepseek_data/DC_Male_197.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_832.txt  \n",
            "  inflating: deepseek_data/DC_Male_514.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_133.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_149.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_577.txt  \n",
            "  inflating: deepseek_data/DC_Female_441.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_990.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_8.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_977.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_962.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_429.txt  \n",
            "  inflating: deepseek_data/DC_Male_125.txt  \n",
            "  inflating: deepseek_data/DC_Female_293.txt  \n",
            "  inflating: deepseek_data/DC_Male_423.txt  \n",
            "  inflating: deepseek_data/DC_Male_950.txt  \n",
            "  inflating: deepseek_data/DC_Female_145.txt  \n",
            "  inflating: deepseek_data/DC_Female_851.txt  \n",
            "  inflating: deepseek_data/DC_Female_203.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_470.txt  \n",
            "  inflating: deepseek_data/DC_Male_767.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_54.txt  \n",
            "  inflating: deepseek_data/DC_Female_336.txt  \n",
            "  inflating: deepseek_data/DC_Male_385.txt  \n",
            "  inflating: deepseek_data/DC_Female_516.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_703.txt  \n",
            "  inflating: deepseek_data/DC_Male_305.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_452.txt  \n",
            "  inflating: deepseek_data/DC_Female_323.txt  \n",
            "  inflating: deepseek_data/DC_Female_810.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_447.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_901.txt  \n",
            "  inflating: deepseek_data/DC_Male_56.txt  \n",
            "  inflating: deepseek_data/DC_Female_854.txt  \n",
            "  inflating: deepseek_data/DC_Female_291.txt  \n",
            "  inflating: deepseek_data/DC_Male_791.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_11.txt  \n",
            "  inflating: deepseek_data/DC_Male_890.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_553.txt  \n",
            "  inflating: deepseek_data/DC_Male_721.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_279.txt  \n",
            "  inflating: deepseek_data/DC_Male_404.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_456.txt  \n",
            "  inflating: deepseek_data/DC_Female_959.txt  \n",
            "  inflating: deepseek_data/DC_Male_337.txt  \n",
            "  inflating: deepseek_data/DC_Male_694.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_322.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_630.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_998.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_49.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_137.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_378.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_625.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_449.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_287.txt  \n",
            "  inflating: deepseek_data/DC_Male_940.txt  \n",
            "  inflating: deepseek_data/DC_Male_248.txt  \n",
            "  inflating: deepseek_data/DC_Female_108.txt  \n",
            "  inflating: deepseek_data/DC_Female_391.txt  \n",
            "  inflating: deepseek_data/DC_Male_598.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_865.txt  \n",
            "  inflating: deepseek_data/DC_Female_623.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_848.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_828.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_642.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_904.txt  \n",
            "  inflating: deepseek_data/DC_Male_591.txt  \n",
            "  inflating: deepseek_data/DC_Female_589.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_84.txt  \n",
            "  inflating: deepseek_data/DC_Female_484.txt  \n",
            "  inflating: deepseek_data/DC_Female_178.txt  \n",
            "  inflating: deepseek_data/DC_Female_957.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_233.txt  \n",
            "  inflating: deepseek_data/DC_Female_316.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_114.txt  \n",
            "  inflating: deepseek_data/DC_Male_520.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_654.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_16.txt  \n",
            "  inflating: deepseek_data/DC_Female_4.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_24.txt  \n",
            "  inflating: deepseek_data/DC_Female_738.txt  \n",
            "  inflating: deepseek_data/DC_Male_88.txt  \n",
            "  inflating: deepseek_data/DC_Female_358.txt  \n",
            "  inflating: deepseek_data/DC_Female_639.txt  \n",
            "  inflating: deepseek_data/DC_Female_800.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_126.txt  \n",
            "  inflating: deepseek_data/DC_Female_603.txt  \n",
            "  inflating: deepseek_data/DC_Male_103.txt  \n",
            "  inflating: deepseek_data/DC_Female_22.txt  \n",
            "  inflating: deepseek_data/DC_Male_270.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_235.txt  \n",
            "  inflating: deepseek_data/DC_Male_354.txt  \n",
            "  inflating: deepseek_data/DC_Male_807.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_989.txt  \n",
            "  inflating: deepseek_data/DC_Female_938.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_348.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_271.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_124.txt  \n",
            "  inflating: deepseek_data/DC_Male_819.txt  \n",
            "  inflating: deepseek_data/DC_Male_153.txt  \n",
            "  inflating: deepseek_data/DC_Male_17.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_905.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_636.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_460.txt  \n",
            "  inflating: deepseek_data/DC_Male_26.txt  \n",
            "  inflating: deepseek_data/DC_Male_975.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_396.txt  \n",
            "  inflating: deepseek_data/DC_Male_580.txt  \n",
            "  inflating: deepseek_data/DC_Female_432.txt  \n",
            "  inflating: deepseek_data/DC_Male_353.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_267.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_286.txt  \n",
            "  inflating: deepseek_data/DC_Female_292.txt  \n",
            "  inflating: deepseek_data/DC_Female_530.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_956.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_405.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_264.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_555.txt  \n",
            "  inflating: deepseek_data/DC_Female_438.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_459.txt  \n",
            "  inflating: deepseek_data/DC_Male_631.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_494.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_917.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_315.txt  \n",
            "  inflating: deepseek_data/DC_Male_894.txt  \n",
            "  inflating: deepseek_data/DC_Male_280.txt  \n",
            "  inflating: deepseek_data/DC_Female_595.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_227.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_709.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_758.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_277.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_878.txt  \n",
            "  inflating: deepseek_data/DC_Male_548.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_352.txt  \n",
            "  inflating: deepseek_data/DC_Female_356.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_770.txt  \n",
            "  inflating: deepseek_data/DC_Male_458.txt  \n",
            "  inflating: deepseek_data/DC_Male_150.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_551.txt  \n",
            "  inflating: deepseek_data/DC_Male_662.txt  \n",
            "  inflating: deepseek_data/DC_Male_343.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_450.txt  \n",
            "  inflating: deepseek_data/DC_Male_482.txt  \n",
            "  inflating: deepseek_data/DC_Male_693.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_674.txt  \n",
            "  inflating: deepseek_data/DC_Male_428.txt  \n",
            "  inflating: deepseek_data/DC_Male_261.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_435.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_982.txt  \n",
            "  inflating: deepseek_data/DC_Female_285.txt  \n",
            "  inflating: deepseek_data/DC_Male_927.txt  \n",
            "  inflating: deepseek_data/DC_Male_495.txt  \n",
            "  inflating: deepseek_data/DC_Male_334.txt  \n",
            "  inflating: deepseek_data/DC_Male_616.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_321.txt  \n",
            "  inflating: deepseek_data/DC_Female_134.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_666.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_550.txt  \n",
            "  inflating: deepseek_data/DC_Female_680.txt  \n",
            "  inflating: deepseek_data/DC_Male_841.txt  \n",
            "  inflating: deepseek_data/DC_Female_364.txt  \n",
            "  inflating: deepseek_data/DC_Female_525.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_257.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_246.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_939.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_727.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_129.txt  \n",
            "  inflating: deepseek_data/DC_Male_748.txt  \n",
            "  inflating: deepseek_data/DC_Female_425.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_660.txt  \n",
            "  inflating: deepseek_data/DC_Male_750.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_42.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_526.txt  \n",
            "  inflating: deepseek_data/DC_Female_144.txt  \n",
            "  inflating: deepseek_data/DC_Female_740.txt  \n",
            "  inflating: deepseek_data/DC_Male_453.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_344.txt  \n",
            "  inflating: deepseek_data/DC_Male_251.txt  \n",
            "  inflating: deepseek_data/DC_Female_31.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_897.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_552.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_719.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_260.txt  \n",
            "  inflating: deepseek_data/DC_Female_504.txt  \n",
            "  inflating: deepseek_data/DC_Female_606.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_139.txt  \n",
            "  inflating: deepseek_data/DC_Male_9.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_418.txt  \n",
            "  inflating: deepseek_data/DC_Male_95.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_213.txt  \n",
            "  inflating: deepseek_data/DC_Female_136.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_774.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_347.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_307.txt  \n",
            "  inflating: deepseek_data/DC_Male_557.txt  \n",
            "  inflating: deepseek_data/DC_Male_211.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_931.txt  \n",
            "  inflating: deepseek_data/DC_Female_439.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_763.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_361.txt  \n",
            "  inflating: deepseek_data/DC_Male_113.txt  \n",
            "  inflating: deepseek_data/DC_Male_581.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_290.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_757.txt  \n",
            "  inflating: deepseek_data/DC_Female_852.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_357.txt  \n",
            "  inflating: deepseek_data/DC_Male_226.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_827.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_443.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_868.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_252.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_220.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_158.txt  \n",
            "  inflating: deepseek_data/DC_Male_67.txt  \n",
            "  inflating: deepseek_data/DC_Female_164.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_469.txt  \n",
            "  inflating: deepseek_data/DC_Female_476.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_89.txt  \n",
            "  inflating: deepseek_data/DC_Female_169.txt  \n",
            "  inflating: deepseek_data/DC_Female_199.txt  \n",
            "  inflating: deepseek_data/DC_Male_156.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_392.txt  \n",
            "  inflating: deepseek_data/DC_Female_883.txt  \n",
            "  inflating: deepseek_data/DC_Female_679.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_320.txt  \n",
            "  inflating: deepseek_data/DC_Male_155.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_40.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_944.txt  \n",
            "  inflating: deepseek_data/DC_Male_234.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_502.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_669.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_923.txt  \n",
            "  inflating: deepseek_data/DC_Female_567.txt  \n",
            "  inflating: deepseek_data/DC_Male_712.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_53.txt  \n",
            "  inflating: deepseek_data/DC_Female_880.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_717.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_866.txt  \n",
            "  inflating: deepseek_data/DC_Male_45.txt  \n",
            "  inflating: deepseek_data/DC_Male_842.txt  \n",
            "  inflating: deepseek_data/DC_Male_661.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_935.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_27.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_281.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_900.txt  \n",
            "  inflating: deepseek_data/DC_Female_907.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_909.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_735.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_783.txt  \n",
            "  inflating: deepseek_data/DC_Male_582.txt  \n",
            "  inflating: deepseek_data/DC_Male_818.txt  \n",
            "  inflating: deepseek_data/DC_Male_881.txt  \n",
            "  inflating: deepseek_data/DC_Male_501.txt  \n",
            "  inflating: deepseek_data/DC_Male_513.txt  \n",
            "  inflating: deepseek_data/DC_Female_119.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_15.txt  \n",
            "  inflating: deepseek_data/DC_Male_647.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_653.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_755.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_902.txt  \n",
            "  inflating: deepseek_data/DC_Female_276.txt  \n",
            "  inflating: deepseek_data/DC_Female_5.txt  \n",
            "  inflating: deepseek_data/DC_Female_172.txt  \n",
            "  inflating: deepseek_data/DC_Female_622.txt  \n",
            "  inflating: deepseek_data/DC_Female_304.txt  \n",
            "  inflating: deepseek_data/DC_Male_332.txt  \n",
            "  inflating: deepseek_data/DC_Male_973.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_991.txt  \n",
            "  inflating: deepseek_data/DC_Male_431.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_269.txt  \n",
            "  inflating: deepseek_data/DC_Female_485.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_611.txt  \n",
            "  inflating: deepseek_data/DC_Male_328.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_911.txt  \n",
            "  inflating: deepseek_data/DC_Male_793.txt  \n",
            "  inflating: deepseek_data/DC_Male_776.txt  \n",
            "  inflating: deepseek_data/DC_Female_115.txt  \n",
            "  inflating: deepseek_data/DC_Male_442.txt  \n",
            "  inflating: deepseek_data/DC_Male_111.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_898.txt  \n",
            "  inflating: deepseek_data/DC_Female_189.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_782.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_645.txt  \n",
            "  inflating: deepseek_data/DC_Male_266.txt  \n",
            "  inflating: deepseek_data/DC_Female_831.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_313.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_436.txt  \n",
            "  inflating: deepseek_data/DC_Female_515.txt  \n",
            "  inflating: deepseek_data/DC_Male_926.txt  \n",
            "  inflating: deepseek_data/DC_Male_471.txt  \n",
            "  inflating: deepseek_data/DC_Male_72.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_857.txt  \n",
            "  inflating: deepseek_data/DC_Male_710.txt  \n",
            "  inflating: deepseek_data/DC_Female_465.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_711.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_331.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_232.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_769.txt  \n",
            "  inflating: deepseek_data/DC_Male_99.txt  \n",
            "  inflating: deepseek_data/DC_Male_565.txt  \n",
            "  inflating: deepseek_data/DC_Male_412.txt  \n",
            "  inflating: deepseek_data/DC_Female_162.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_402.txt  \n",
            "  inflating: deepseek_data/DC_Female_289.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_498.txt  \n",
            "  inflating: deepseek_data/DC_Male_812.txt  \n",
            "  inflating: deepseek_data/DC_Female_23.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_446.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_771.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_318.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_701.txt  \n",
            "  inflating: deepseek_data/DC_Female_876.txt  \n",
            "  inflating: deepseek_data/DC_Male_765.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_338.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_489.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_980.txt  \n",
            "  inflating: deepseek_data/DC_Female_367.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_659.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_869.txt  \n",
            "  inflating: deepseek_data/DC_Male_576.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_138.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_889.txt  \n",
            "  inflating: deepseek_data/DC_Female_929.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_749.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_528.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_69.txt  \n",
            "  inflating: deepseek_data/DC_Female_414.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_874.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_967.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_736.txt  \n",
            "  inflating: deepseek_data/DC_Male_529.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_813.txt  \n",
            "  inflating: deepseek_data/DC_Male_411.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_707.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_687.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_339.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_41.txt  \n",
            "  inflating: deepseek_data/DC_Male_406.txt  \n",
            "  inflating: deepseek_data/DC_Female_263.txt  \n",
            "  inflating: deepseek_data/DC_Male_314.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_132.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_33.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_104.txt  \n",
            "  inflating: deepseek_data/DC_Male_231.txt  \n",
            "  inflating: deepseek_data/DC_Female_122.txt  \n",
            "  inflating: deepseek_data/DC_Female_499.txt  \n",
            "  inflating: deepseek_data/DC_Male_186.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_784.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_965.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_633.txt  \n",
            "  inflating: deepseek_data/DC_Female_751.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_7.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_350.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_20.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_986.txt  \n",
            "  inflating: deepseek_data/DC_Female_59.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_490.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_379.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_82.txt  \n",
            "  inflating: deepseek_data/DC_Female_272.txt  \n",
            "  inflating: deepseek_data/DC_Male_903.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_377.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_932.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_375.txt  \n",
            "  inflating: deepseek_data/DC_Female_395.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_94.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_216.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_312.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_815.txt  \n",
            "  inflating: deepseek_data/DC_Female_608.txt  \n",
            "  inflating: deepseek_data/DC_Female_850.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_173.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_278.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_629.txt  \n",
            "  inflating: deepseek_data/DC_Female_652.txt  \n",
            "  inflating: deepseek_data/DC_Female_77.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_947.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_83.txt  \n",
            "  inflating: deepseek_data/DC_Male_330.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_207.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_668.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_427.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_349.txt  \n",
            "  inflating: deepseek_data/DC_Male_861.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_92.txt  \n",
            "  inflating: deepseek_data/DC_Female_593.txt  \n",
            "  inflating: deepseek_data/DC_Female_419.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_615.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_673.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_229.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_492.txt  \n",
            "  inflating: deepseek_data/DC_Female_723.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_182.txt  \n",
            "  inflating: deepseek_data/DC_Female_325.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_839.txt  \n",
            "  inflating: deepseek_data/DC_Male_794.txt  \n",
            "  inflating: deepseek_data/DC_Female_996.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_658.txt  \n",
            "  inflating: deepseek_data/DC_Female_537.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_376.txt  \n",
            "  inflating: deepseek_data/DC_Male_118.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_296.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_764.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_775.txt  \n",
            "  inflating: deepseek_data/DC_Male_205.txt  \n",
            "  inflating: deepseek_data/DC_Male_700.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_522.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_6.txt  \n",
            "  inflating: deepseek_data/DC_Female_382.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_224.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_974.txt  \n",
            "  inflating: deepseek_data/DC_Female_198.txt  \n",
            "  inflating: deepseek_data/DC_Male_478.txt  \n",
            "  inflating: deepseek_data/DC_Female_415.txt  \n",
            "  inflating: deepseek_data/DC_Female_924.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_836.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_87.txt  \n",
            "  inflating: deepseek_data/DC_Female_560.txt  \n",
            "  inflating: deepseek_data/DC_Female_799.txt  \n",
            "  inflating: deepseek_data/DC_Male_732.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_362.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_32.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_994.txt  \n",
            "  inflating: deepseek_data/DC_Female_238.txt  \n",
            "  inflating: deepseek_data/DC_Male_210.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_363.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_877.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_389.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_390.txt  \n",
            "  inflating: deepseek_data/DC_Female_949.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_444.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_790.txt  \n",
            "  inflating: deepseek_data/DC_Male_237.txt  \n",
            "  inflating: deepseek_data/DC_Male_409.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_718.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_592.txt  \n",
            "  inflating: deepseek_data/DC_Male_74.txt  \n",
            "  inflating: deepseek_data/DC_Female_814.txt  \n",
            "  inflating: deepseek_data/DC_Male_683.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_236.txt  \n",
            "  inflating: deepseek_data/DC_Male_788.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_720.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_299.txt  \n",
            "  inflating: deepseek_data/DC_Male_651.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_886.txt  \n",
            "  inflating: deepseek_data/DC_Female_30.txt  \n",
            "  inflating: deepseek_data/DC_Female_627.txt  \n",
            "  inflating: deepseek_data/DC_Female_893.txt  \n",
            "  inflating: deepseek_data/DC_Female_50.txt  \n",
            "  inflating: deepseek_data/DC_Female_300.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_859.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_954.txt  \n",
            "  inflating: deepseek_data/DC_Female_93.txt  \n",
            "  inflating: deepseek_data/DC_Male_508.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_960.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_708.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_455.txt  \n",
            "  inflating: deepseek_data/DC_Female_239.txt  \n",
            "  inflating: deepseek_data/DC_Male_588.txt  \n",
            "  inflating: deepseek_data/DC_Male_823.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_614.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_789.txt  \n",
            "  inflating: deepseek_data/DC_Male_18.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_569.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_35.txt  \n",
            "  inflating: deepseek_data/DC_Female_142.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_472.txt  \n",
            "  inflating: deepseek_data/DC_Female_262.txt  \n",
            "  inflating: deepseek_data/DC_Male_845.txt  \n",
            "  inflating: deepseek_data/DC_Male_545.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_858.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_885.txt  \n",
            "  inflating: deepseek_data/DC_Male_584.txt  \n",
            "  inflating: deepseek_data/DC_Female_163.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_966.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_212.txt  \n",
            "  inflating: deepseek_data/DC_Female_804.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_206.txt  \n",
            "  inflating: deepseek_data/DC_Male_62.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_78.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_511.txt  \n",
            "  inflating: deepseek_data/DC_Female_13.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_242.txt  \n",
            "  inflating: deepseek_data/DC_Female_572.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_657.txt  \n",
            "  inflating: deepseek_data/DC_Female_507.txt  \n",
            "  inflating: deepseek_data/DC_Male_867.txt  \n",
            "  inflating: deepseek_data/DC_Female_75.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_540.txt  \n",
            "  inflating: deepseek_data/DC_Female_706.txt  \n",
            "  inflating: deepseek_data/DC_Female_518.txt  \n",
            "  inflating: deepseek_data/DC_Female_993.txt  \n",
            "  inflating: deepseek_data/DC_Female_697.txt  \n",
            "  inflating: deepseek_data/DC_Female_691.txt  \n",
            "  inflating: deepseek_data/DC_Female_872.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_380.txt  \n",
            "  inflating: deepseek_data/DC_Female_503.txt  \n",
            "  inflating: deepseek_data/DC_Female_834.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_734.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_534.txt  \n",
            "  inflating: deepseek_data/DC_Male_678.txt  \n",
            "  inflating: deepseek_data/DC_Male_175.txt  \n",
            "  inflating: deepseek_data/DC_Female_65.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_637.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_188.txt  \n",
            "  inflating: deepseek_data/DC_Male_106.txt  \n",
            "  inflating: deepseek_data/DC_Male_737.txt  \n",
            "  inflating: deepseek_data/DC_Male_785.txt  \n",
            "  inflating: deepseek_data/DC_Male_160.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_167.txt  \n",
            "  inflating: deepseek_data/DC_Female_37.txt  \n",
            "  inflating: deepseek_data/DC_Male_539.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_698.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_583.txt  \n",
            "  inflating: deepseek_data/DC_Male_992.txt  \n",
            "  inflating: deepseek_data/DC_Female_871.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_665.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_43.txt  \n",
            "  inflating: deepseek_data/DC_Male_840.txt  \n",
            "  inflating: deepseek_data/DC_Female_928.txt  \n",
            "  inflating: deepseek_data/DC_Female_473.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_596.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_605.txt  \n",
            "  inflating: deepseek_data/DC_Female_677.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_803.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_997.txt  \n",
            "  inflating: deepseek_data/DC_Female_801.txt  \n",
            "  inflating: deepseek_data/DC_Male_143.txt  \n",
            "  inflating: deepseek_data/DC_Female_243.txt  \n",
            "  inflating: deepseek_data/DC_Female_780.txt  \n",
            "  inflating: deepseek_data/DC_Female_561.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_656.txt  \n",
            "  inflating: deepseek_data/DC_Male_704.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_533.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_309.txt  \n",
            "  inflating: deepseek_data/DC_Male_154.txt  \n",
            "  inflating: deepseek_data/DC_Male_971.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_816.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_612.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_726.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_809.txt  \n",
            "  inflating: deepseek_data/DC_Female_302.txt  \n",
            "  inflating: deepseek_data/DC_Male_756.txt  \n",
            "  inflating: deepseek_data/DC_Male_245.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_760.txt  \n",
            "  inflating: deepseek_data/DC_Female_754.txt  \n",
            "  inflating: deepseek_data/DC_Male_319.txt  \n",
            "  inflating: deepseek_data/DC_Male_618.txt  \n",
            "  inflating: deepseek_data/DC_Female_341.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_925.txt  \n",
            "  inflating: deepseek_data/DC_Male_820.txt  \n",
            "  inflating: deepseek_data/DC_Male_510.txt  \n",
            "  inflating: deepseek_data/DC_Male_684.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_34.txt  \n",
            "  inflating: deepseek_data/DC_Female_297.txt  \n",
            "  inflating: deepseek_data/DC_Female_532.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_733.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_937.txt  \n",
            "  inflating: deepseek_data/DC_Male_369.txt  \n",
            "  inflating: deepseek_data/DC_Male_288.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_39.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_672.txt  \n",
            "  inflating: deepseek_data/DC_Female_617.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_176.txt  \n",
            "  inflating: deepseek_data/DC_Female_454.txt  \n",
            "  inflating: deepseek_data/DC_Male_384.txt  \n",
            "  inflating: deepseek_data/DC_Female_61.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_497.txt  \n",
            "  inflating: deepseek_data/DC_Female_742.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_912.txt  \n",
            "  inflating: deepseek_data/DC_Male_101.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_825.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_978.txt  \n",
            "  inflating: deepseek_data/DC_Male_644.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_941.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_696.txt  \n",
            "  inflating: deepseek_data/DC_Female_2.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_543.txt  \n",
            "  inflating: deepseek_data/DC_Female_79.txt  \n",
            "  inflating: deepseek_data/DC_Female_195.txt  \n",
            "  inflating: deepseek_data/DC_Male_916.txt  \n",
            "  inflating: deepseek_data/DC_Female_682.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_141.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_311.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_193.txt  \n",
            "  inflating: deepseek_data/DC_Female_620.txt  \n",
            "  inflating: deepseek_data/DC_Female_610.txt  \n",
            "  inflating: deepseek_data/DC_Male_310.txt  \n",
            "  inflating: deepseek_data/DC_Female_922.txt  \n",
            "  inflating: deepseek_data/DC_Male_387.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_179.txt  \n",
            "  inflating: deepseek_data/DC_Male_183.txt  \n",
            "  inflating: deepseek_data/DC_Female_381.txt  \n",
            "  inflating: deepseek_data/DC_Female_613.txt  \n",
            "  inflating: deepseek_data/DC_Male_493.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_121.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_837.txt  \n",
            "  inflating: deepseek_data/DC_Male_744.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_843.txt  \n",
            "  inflating: deepseek_data/DC_Male_976.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_999.txt  \n",
            "  inflating: deepseek_data/DC_Male_918.txt  \n",
            "  inflating: deepseek_data/DC_Female_542.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_747.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_895.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_702.txt  \n",
            "  inflating: deepseek_data/DC_Male_715.txt  \n",
            "  inflating: deepseek_data/DC_Male_240.txt  \n",
            "  inflating: deepseek_data/DC_Male_25.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_607.txt  \n",
            "  inflating: deepseek_data/DC_Male_955.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_729.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_152.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_870.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_817.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_228.txt  \n",
            "  inflating: deepseek_data/DC_Female_559.txt  \n",
            "  inflating: deepseek_data/DC_Female_946.txt  \n",
            "  inflating: deepseek_data/DC_Female_60.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_481.txt  \n",
            "  inflating: deepseek_data/DC_Female_739.txt  \n",
            "  inflating: deepseek_data/DC_Male_619.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_600.txt  \n",
            "  inflating: deepseek_data/DC_Female_477.txt  \n",
            "  inflating: deepseek_data/DC_Female_549.txt  \n",
            "  inflating: deepseek_data/DC_Male_283.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_187.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_424.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_219.txt  \n",
            "  inflating: deepseek_data/DC_Male_796.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_366.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_335.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_487.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_468.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_995.txt  \n",
            "  inflating: deepseek_data/DC_Male_98.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_649.txt  \n",
            "  inflating: deepseek_data/DC_Female_408.txt  \n",
            "  inflating: deepseek_data/DC_Female_571.txt  \n",
            "  inflating: deepseek_data/DC_Male_66.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_806.txt  \n",
            "  inflating: deepseek_data/DC_Female_527.txt  \n",
            "  inflating: deepseek_data/DC_Female_222.txt  \n",
            "  inflating: deepseek_data/DC_Male_273.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_943.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_159.txt  \n",
            "  inflating: deepseek_data/DC_Male_112.txt  \n",
            "  inflating: deepseek_data/DC_Male_853.txt  \n",
            "  inflating: deepseek_data/DC_Female_102.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_177.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_171.txt  \n",
            "  inflating: deepseek_data/DC_Female_140.txt  \n",
            "  inflating: deepseek_data/DC_Female_359.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_802.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_209.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_342.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_372.txt  \n",
            "  inflating: deepseek_data/DC_Female_434.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_628.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_201.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_192.txt  \n",
            "  inflating: deepseek_data/DC_Male_979.txt  \n",
            "  inflating: deepseek_data/DC_Female_624.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_295.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_578.txt  \n",
            "  inflating: deepseek_data/DC_Female_671.txt  \n",
            "  inflating: deepseek_data/DC_Female_544.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_879.txt  \n",
            "  inflating: deepseek_data/DC_Female_208.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_795.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_3.txt  \n",
            "  inflating: deepseek_data/DC_Female_884.txt  \n",
            "  inflating: deepseek_data/DC_Male_479.txt  \n",
            "  inflating: deepseek_data/DC_Female_448.txt  \n",
            "  inflating: deepseek_data/DC_Female_486.txt  \n",
            "  inflating: deepseek_data/DC_Female_46.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_365.txt  \n",
            "  inflating: deepseek_data/DC_Male_131.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_445.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_463.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_523.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_579.txt  \n",
            "  inflating: deepseek_data/DC_Male_792.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_985.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_983.txt  \n",
            "  inflating: deepseek_data/DC_Female_221.txt  \n",
            "  inflating: deepseek_data/DC_Female_829.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_420.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_265.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_329.txt  \n",
            "  inflating: deepseek_data/DC_Female_71.txt  \n",
            "  inflating: deepseek_data/DC_Male_170.txt  \n",
            "  inflating: deepseek_data/DC_Male_716.txt  \n",
            "  inflating: deepseek_data/DC_Male_833.txt  \n",
            "  inflating: deepseek_data/DC_Female_214.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_397.txt  \n",
            "  inflating: deepseek_data/DC_Female_538.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_464.txt  \n",
            "  inflating: deepseek_data/DC_Male_120.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_96.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_891.txt  \n",
            "  inflating: deepseek_data/DC_Male_915.txt  \n",
            "  inflating: deepseek_data/DC_Female_936.txt  \n",
            "  inflating: deepseek_data/DC_Male_873.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_863.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_988.txt  \n",
            "  inflating: deepseek_data/DC_Female_650.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_303.txt  \n",
            "  inflating: deepseek_data/DC_Male_838.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_326.txt  \n",
            "  inflating: deepseek_data/DC_Male_64.txt  \n",
            "  inflating: deepseek_data/DC_Female_968.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_835.txt  \n",
            "  inflating: deepseek_data/DC_Male_786.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_855.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_368.txt  \n",
            "  inflating: deepseek_data/DC_Male_731.txt  \n",
            "  inflating: deepseek_data/DC_Female_808.txt  \n",
            "  inflating: deepseek_data/DC_Male_253.txt  \n",
            "  inflating: deepseek_data/DC_Male_984.txt  \n",
            "  inflating: deepseek_data/DC_Male_467.txt  \n",
            "  inflating: deepseek_data/DC_Female_247.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_822.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_821.txt  \n",
            "  inflating: deepseek_data/DC_Female_200.txt  \n",
            "  inflating: deepseek_data/DC_Male_862.txt  \n",
            "  inflating: deepseek_data/DC_Male_892.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_1.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_146.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_480.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_426.txt  \n",
            "  inflating: deepseek_data/DC_Male_963.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_100.txt  \n",
            "  inflating: deepseek_data/DC_Female_951.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_80.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_259.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_58.txt  \n",
            "  inflating: deepseek_data/DC_Female_599.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_196.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_690.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_55.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_90.txt  \n",
            "  inflating: deepseek_data/DC_Male_437.txt  \n",
            "  inflating: deepseek_data/DC_Female_398.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_787.txt  \n",
            "  inflating: deepseek_data/DC_Male_688.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_151.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_416.txt  \n",
            "  inflating: deepseek_data/DC_Female_107.txt  \n",
            "  inflating: deepseek_data/DC_Male_601.txt  \n",
            "  inflating: deepseek_data/DC_Male_308.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_692.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_594.txt  \n",
            "  inflating: deepseek_data/DC_Male_689.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_587.txt  \n",
            "  inflating: deepseek_data/DC_Male_741.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_686.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_218.txt  \n",
            "  inflating: deepseek_data/DC_Male_805.txt  \n",
            "  inflating: deepseek_data/DC_Female_830.txt  \n",
            "  inflating: deepseek_data/DC_Female_217.txt  \n",
            "  inflating: deepseek_data/DC_Female_407.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_746.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_846.txt  \n",
            "  inflating: deepseek_data/DC_Female_400.txt  \n",
            "  inflating: deepseek_data/DC_Male_536.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_433.txt  \n",
            "  inflating: deepseek_data/DC_Male_91.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_509.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_109.txt  \n",
            "  inflating: deepseek_data/DC_Male_970.txt  \n",
            "  inflating: deepseek_data/DC_Female_421.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_393.txt  \n",
            "  inflating: deepseek_data/DC_Male_505.txt  \n",
            "  inflating: deepseek_data/DC_Male_135.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_762.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_123.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_913.txt  \n",
            "  inflating: deepseek_data/DC_Female_779.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_566.txt  \n",
            "  inflating: deepseek_data/DC_Female_546.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_899.txt  \n",
            "  inflating: deepseek_data/DC_Female_930.txt  \n",
            "  inflating: deepseek_data/DC_Male_568.txt  \n",
            "  inflating: deepseek_data/DC_Male_491.txt  \n",
            "  inflating: deepseek_data/DC_Female_640.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_864.txt  \n",
            "  inflating: deepseek_data/DC_Female_554.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_0.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_585.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_44.txt  \n",
            "  inflating: deepseek_data/DC_Female_675.txt  \n",
            "  inflating: deepseek_data/DC_Female_714.txt  \n",
            "  inflating: deepseek_data/DC_Male_604.txt  \n",
            "  inflating: deepseek_data/DC_Female_626.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_921.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_705.txt  \n",
            "  inflating: deepseek_data/DC_Male_981.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_496.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_722.txt  \n",
            "  inflating: deepseek_data/DC_Male_194.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_641.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_541.txt  \n",
            "  inflating: deepseek_data/DC_Female_964.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_521.txt  \n",
            "  inflating: deepseek_data/DC_Female_570.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_127.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_110.txt  \n",
            "  inflating: deepseek_data/DC_Male_663.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_597.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_766.txt  \n",
            "  inflating: deepseek_data/DC_Male_942.txt  \n",
            "  inflating: deepseek_data/DC_Male_180.txt  \n",
            "  inflating: deepseek_data/DC_Male_952.txt  \n",
            "  inflating: deepseek_data/DC_Female_401.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_148.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_374.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_768.txt  \n",
            "  inflating: deepseek_data/DC_Female_370.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_761.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_47.txt  \n",
            "  inflating: deepseek_data/DC_Female_440.txt  \n",
            "  inflating: deepseek_data/DC_Male_634.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_664.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_68.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_797.txt  \n",
            "  inflating: deepseek_data/DC_Female_730.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_327.txt  \n",
            "  inflating: deepseek_data/DC_Female_181.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_500.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_745.txt  \n",
            "  inflating: deepseek_data/DC_Female_777.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_386.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_461.txt  \n",
            "  inflating: deepseek_data/DC_Male_373.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_10.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_223.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_130.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_643.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_165.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_76.txt  \n",
            "  inflating: deepseek_data/DC_Male_230.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_268.txt  \n",
            "  inflating: deepseek_data/DC_Female_274.txt  \n",
            "  inflating: deepseek_data/DC_Male_826.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_483.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_655.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_547.txt  \n",
            "  inflating: deepseek_data/DC_Female_355.txt  \n",
            "  inflating: deepseek_data/DC_Male_430.txt  \n",
            "  inflating: deepseek_data/DC_Male_70.txt  \n",
            "  inflating: deepseek_data/DC_Male_166.txt  \n",
            "  inflating: deepseek_data/DC_Male_202.txt  \n",
            "  inflating: deepseek_data/DC_Female_14.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_422.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_301.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_953.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_517.txt  \n",
            "  inflating: deepseek_data/DC_Male_117.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_535.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_638.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_676.txt  \n",
            "  inflating: deepseek_data/DC_Female_488.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_73.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_185.txt  \n",
            "  inflating: deepseek_data/DC_Male_403.txt  \n",
            "  inflating: deepseek_data/DC_Male_86.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_255.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_961.txt  \n",
            "  inflating: deepseek_data/DC_Male_573.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_621.txt  \n",
            "  inflating: deepseek_data/DC_Male_933.txt  \n",
            "  inflating: deepseek_data/DC_Female_360.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_244.txt  \n",
            "  inflating: deepseek_data/DC_Male_466.txt  \n",
            "  inflating: deepseek_data/DC_Female_28.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_105.txt  \n",
            "  inflating: deepseek_data/DC_Female_161.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_908.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_781.txt  \n",
            "  inflating: deepseek_data/DC_Female_681.txt  \n",
            "  inflating: deepseek_data/DC_Female_21.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_919.txt  \n",
            "  inflating: deepseek_data/DC_Female_875.txt  \n",
            "  inflating: deepseek_data/DC_Male_724.txt  \n",
            "  inflating: deepseek_data/DC_Female_38.txt  \n",
            "  inflating: deepseek_data/DC_Female_48.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_728.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_191.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_85.txt  \n",
            "  inflating: deepseek_data/DC_Male_147.txt  \n",
            "  inflating: deepseek_data/DC_Female_972.txt  \n",
            "  inflating: deepseek_data/DC_Male_699.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_753.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_969.txt  \n",
            "  inflating: deepseek_data/DC_Female_773.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_914.txt  \n",
            "  inflating: deepseek_data/DC_Male_410.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_215.txt  \n",
            "  inflating: deepseek_data/DC_Male_351.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_63.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_340.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_506.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_667.txt  \n",
            "  inflating: deepseek_data/DC_Female_184.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_906.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_860.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_29.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_457.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_306.txt  \n",
            "  inflating: deepseek_data/DC_Female_574.txt  \n",
            "  inflating: deepseek_data/DC_Male_451.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_254.txt  \n",
            "  inflating: deepseek_data/DC_Female_317.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_752.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_475.txt  \n",
            "  inflating: deepseek_data/DC_Male_81.txt  \n",
            "  inflating: deepseek_data/DC_Female_888.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_462.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_57.txt  \n",
            "  inflating: deepseek_data/DC_Female_519.txt  \n",
            "  inflating: deepseek_data/DC_Female_685.txt  \n",
            "  inflating: deepseek_data/DC_Male_934.txt  \n",
            "  inflating: deepseek_data/DC_Male_346.txt  \n",
            "  inflating: deepseek_data/DC_Female_945.txt  \n",
            "  inflating: deepseek_data/DC_Male_413.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_759.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_394.txt  \n",
            "  inflating: deepseek_data/DC_Female_258.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_948.txt  \n",
            "  inflating: deepseek_data/DC_Female_887.txt  \n",
            "  inflating: deepseek_data/DC_Female_298.txt  \n",
            "  inflating: deepseek_data/DC_Female_12.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_97.txt  \n",
            "  inflating: deepseek_data/DC_Male_157.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_772.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_284.txt  \n",
            "  inflating: deepseek_data/DC_Male_558.txt  \n",
            "  inflating: deepseek_data/DC_Female_844.txt  \n",
            "  inflating: deepseek_data/DC_Female_474.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_399.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_388.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_609.txt  \n",
            "  inflating: deepseek_data/Princeville_Female_632.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_19.txt  \n",
            "  inflating: deepseek_data/DC_Male_36.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_910.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_417.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_531.txt  \n",
            "  inflating: deepseek_data/DC_Female_646.txt  \n",
            "  inflating: deepseek_data/DC_Male_849.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_564.txt  \n",
            "  inflating: deepseek_data/DC_Female_256.txt  \n",
            "  inflating: deepseek_data/DC_Male_920.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_190.txt  \n",
            "  inflating: deepseek_data/DC_Female_524.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_275.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Male_333.txt  \n",
            "  inflating: deepseek_data/DC_Male_811.txt  \n",
            "  inflating: deepseek_data/DC_Female_556.txt  \n",
            "  inflating: deepseek_data/DC_Female_512.txt  \n",
            "  inflating: deepseek_data/DC_Female_294.txt  \n",
            "  inflating: deepseek_data/Valdosta_Female_670.txt  \n",
            "  inflating: deepseek_data/DC_Female_847.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_563.txt  \n",
            "  inflating: deepseek_data/DC_Female_648.txt  \n",
            "  inflating: deepseek_data/DC_Male_590.txt  \n",
            "  inflating: deepseek_data/DC_Male_345.txt  \n",
            "  inflating: deepseek_data/DC_Female_586.txt  \n",
            "  inflating: deepseek_data/Detroit_Male_695.txt  \n",
            "  inflating: deepseek_data/Rochester_Male_241.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_798.txt  \n",
            "  inflating: deepseek_data/Valdosta_Male_51.txt  \n",
            "  inflating: deepseek_data/Rochester_Female_225.txt  \n",
            "  inflating: deepseek_data/Atlanta_Male_635.txt  \n",
            "  inflating: deepseek_data/Detroit_Female_778.txt  \n",
            "  inflating: deepseek_data/Atlanta_Female_824.txt  \n",
            "  inflating: deepseek_data/DC_Female_856.txt  \n",
            "  inflating: deepseek_data/DC_Male_575.txt  \n",
            "  inflating: deepseek_data/DC_Female_713.txt  \n",
            "  inflating: deepseek_data/Lower East Side of New York City_Female_52.txt  \n",
            "  inflating: deepseek_data/Princeville_Male_204.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "# Unzip the file\n",
        "!unzip google_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "collapsed": true,
        "id": "F1RVM_RIvJ7a",
        "outputId": "5b7ffb6e-eb9b-48e1-c721-d16e110092e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a27db6d8-89c6-459c-8d01-aa76dedcf4ab\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a27db6d8-89c6-459c-8d01-aa76dedcf4ab\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-4cc4dab062cc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Unzip the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unzip google_data.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "# Unzip the file\n",
        "!unzip data.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "S1-eZCfVvM1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Analysis\n",
        "\n",
        "Below is an example of running the `ran_sentences` function, that randomly chooses ten sentences from the dataset to be able to get a general glimpse into the dataset."
      ],
      "metadata": {
        "id": "k_m6WM-EnQyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai_AAVE = AAVE_Feature(folder = \"./openai_data\")\n",
        "\n",
        "openai_AAVE.read_files(human=False)\n",
        "print(openai_AAVE.ran_sentences())"
      ],
      "metadata": {
        "id": "4sgWY5ISrhZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuL8DY7SRmZe"
      },
      "source": [
        "# Feature Detection\n",
        "\n",
        "Run the following code chunk below to all of the relevant data points in an intepretable manner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3BQDeK1Tyoc"
      },
      "outputs": [],
      "source": [
        "# collects the human probabilites for the features from the dataset\n",
        "human_AAVE = AAVE_Feature(folder = \"./data\")\n",
        "human_AAVE.read_files()\n",
        "human_AAVE.n_grams()\n",
        "\n",
        "for feature in [\"ain't\", \"negative\", \"be\"]:\n",
        "  human_AAVE.lexical_feature(feature)\n",
        "  human_AAVE.feature_densities(feature)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dislplay context-specific feature probabilities\n",
        "human_AAVE.feature_prob"
      ],
      "metadata": {
        "id": "XTCQ7ZK4FmOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display feature density\n",
        "human_AAVE.feature_density"
      ],
      "metadata": {
        "id": "XRiIuQ-cFnxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sF28ZDL3Ioh8"
      },
      "outputs": [],
      "source": [
        "openai_AAVE = AAVE_Feature(folder = \"./openai_data\")\n",
        "\n",
        "# read in the files from the dataset\n",
        "openai_AAVE.read_files(human=False)\n",
        "openai_AAVE.n_grams()\n",
        "\n",
        "# calculate context specific feature densities for be and aint features\n",
        "for feature in [\"ain't\",'be']:\n",
        "  openai_AAVE.lexical_feature(feature, human=False, human_keys = human_AAVE.feature_prob[feature].keys())\n",
        "  openai_AAVE.feature_densities(feature)\n",
        "\n",
        "# calculate feature densities for double negative feature\n",
        "openai_AAVE.feature_densities('negative')\n",
        "openai_AAVE.lexical_feature('negative')\n",
        "\n",
        "# display densities\n",
        "print(openai_AAVE.feature_prob)\n",
        "print(openai_AAVE.feature_density)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53Noi1-oyDos"
      },
      "outputs": [],
      "source": [
        "meta_AAVE = AAVE_Feature(folder = \"./meta_data\")\n",
        "\n",
        "# read in the files from the dataset\n",
        "meta_AAVE.read_files(human=False)\n",
        "meta_AAVE.n_grams()\n",
        "\n",
        "# calculate context specific feature densities for be and aint features\n",
        "for feature in [\"ain't\",'be']:\n",
        "  meta_AAVE.lexical_feature(feature, human=False, human_keys = human_AAVE.feature_prob[feature].keys())\n",
        "  meta_AAVE.feature_densities(feature)\n",
        "\n",
        "# calculate feature densities for double negative feature\n",
        "meta_AAVE.feature_densities('negative')\n",
        "meta_AAVE.lexical_feature('negative')\n",
        "\n",
        "# display densities\n",
        "print(meta_AAVE.feature_prob)\n",
        "print(meta_AAVE.feature_density)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google_AAVE = AAVE_Feature(folder = \"./google_data\")\n",
        "\n",
        "# read in the files from the dataset\n",
        "google_AAVE.read_files(human=False)\n",
        "google_AAVE.n_grams()\n",
        "\n",
        "# calculate context specific feature densities for be and aint features\n",
        "for feature in [\"ain't\",'be']:\n",
        "  google_AAVE.lexical_feature(feature, human=False, human_keys = human_AAVE.feature_prob[feature].keys())\n",
        "  google_AAVE.feature_densities(feature)\n",
        "\n",
        "# calculate feature densities for double negative feature\n",
        "google_AAVE.feature_densities('negative')\n",
        "google_AAVE.lexical_feature('negative')\n",
        "\n",
        "# display densities\n",
        "print(google_AAVE.feature_prob)\n",
        "print(google_AAVE.feature_density)"
      ],
      "metadata": {
        "id": "bSobluSBFvXy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}